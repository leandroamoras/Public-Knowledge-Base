{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark #02\n",
    "\n",
    "Link da Aula: [PySpark - Aula 02 - Window Functions - Português - Hands On](https://www.youtube.com/watch?v=MG-QBpEXvjg&t=1851s)\n",
    "\n",
    "**Indice:**\n",
    "\n",
    "- [Importacão bibliotecas/funcões](#importacão-bibliotecasfuncões)\n",
    "- [Iniciando sessão PySpark](#iniciando-sessão-pyspark)\n",
    "- [Criar DF/ler arquivo](#criar-dfler-arquivo)\n",
    "- [Renomeando colunas](#renomeando-colunas)\n",
    "- [Drop de colunas](#drop-de-colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importacão bibliotecas/funcões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iniciando sessão PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local')\n",
    "    .appName('PySpark_02')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criar DF/ler arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----+------------------+----------+----------+--------------------+------+------+\n",
      "|     Team|  #|Pos.| FIFA Popular Name|Birth Date|Shirt Name|                Club|Height|Weight|\n",
      "+---------+---+----+------------------+----------+----------+--------------------+------+------+\n",
      "|Argentina|  3|  DF|TAGLIAFICO Nicolas|31.08.1992|TAGLIAFICO|      AFC Ajax (NED)|   169|    65|\n",
      "|Argentina| 22|  MF|    PAVON Cristian|21.01.1996|     PAVÓN|CA Boca Juniors (...|   169|    65|\n",
      "|Argentina| 15|  MF|    LANZINI Manuel|15.02.1993|   LANZINI|West Ham United F...|   167|    66|\n",
      "|Argentina| 18|  DF|    SALVIO Eduardo|13.07.1990|    SALVIO|    SL Benfica (POR)|   167|    69|\n",
      "|Argentina| 10|  FW|      MESSI Lionel|24.06.1987|     MESSI|  FC Barcelona (ESP)|   170|    72|\n",
      "+---------+---+----+------------------+----------+----------+--------------------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('wc2018-players.csv', header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Renomeando colunas\n",
    "\n",
    ">\"Diferente do Pandas, o Spark é imutável. Ou Seja, se voce subistituir o nome da coluna de um DF no Spark, nao dá pra usar o parametro inplace=True! Para resolver isso, voce deve fazer o código abaixo. \"\n",
    "\n",
    "```python:\n",
    "df = df.withColumnRenamed('Nome Antigo','Novo Nome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Selecao: string (nullable = true)\n",
      " |-- Numero: integer (nullable = true)\n",
      " |-- Posicao: string (nullable = true)\n",
      " |-- Nome_FIFA: string (nullable = true)\n",
      " |-- Nascimento: string (nullable = true)\n",
      " |-- Nome Camiseta: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Altura: integer (nullable = true)\n",
      " |-- Peso: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Renomeando todas colunas\n",
    "df = df.withColumnRenamed('Team','Selecao').withColumnRenamed('#','Numero')\\\n",
    ".withColumnRenamed('Pos.','Posicao').withColumnRenamed('FIFA Popular Name','Nome_FIFA')\\\n",
    ".withColumnRenamed('Birth Date','Nascimento')\\\n",
    ".withColumnRenamed('Shirt Name','Nome Camiseta').withColumnRenamed('Club','Time')\\\n",
    ".withColumnRenamed('Height','Altura').withColumnRenamed('Weight','Peso')\n",
    "\n",
    "#Verificando alteracões\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Selecao: string (nullable = true)\n",
      " |-- Numero: integer (nullable = true)\n",
      " |-- Posicao: string (nullable = true)\n",
      " |-- Nome_FIFA: string (nullable = true)\n",
      " |-- Nome Camiseta: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Altura: integer (nullable = true)\n",
      " |-- Peso: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Removendo a coluna\n",
    "df = df.drop('Nascimento')\n",
    "\n",
    "#Verificando se a coluna foi removida\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "388205e5731b4f355eaaff016a45c2f47ce51ebec73bddfe135d5f542472dd84"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
